{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Capstone #\n",
    "\n",
    "## ArXiv Topic Clustering ##\n",
    "\n",
    "#### Overview ####\n",
    "\n",
    "ArXiv is a repository consisting of over 1.5 million scientific papers in fields such as mathematics, computer science, and physics. It is owned and operated by Cornell University.\n",
    "\n",
    "This capstone will explore the use of different clustering methods to predict the topic of each paper. I will be attempting to use K-Means, DBSCAN (Density-based Spatial Clustering of Applications with Noise), and the Gaussian Mixture Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arxiv\n",
    "import spacy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = arxiv.query(\"all\",max_results=100000)\n",
    "\n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different topics discussed in the arXiv scientific papers. I will be focusing solely on mathematics, computer science, and physics. As such I have imported 100,000 papers so I will be able to grab only 1000 of each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affiliation</th>\n",
       "      <th>arxiv_comment</th>\n",
       "      <th>arxiv_primary_category</th>\n",
       "      <th>arxiv_url</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>authors</th>\n",
       "      <th>doi</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'term': 'math.NA', 'scheme': 'http://arxiv.or...</td>\n",
       "      <td>http://arxiv.org/abs/1210.7708v1</td>\n",
       "      <td>Alexei Shadrin</td>\n",
       "      <td>{'name': 'Alexei Shadrin'}</td>\n",
       "      <td>[Alexei Shadrin]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/1210.7708v1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1210.7708v1</td>\n",
       "      <td>2012-10-29T16:12:41Z</td>\n",
       "      <td>(2012, 10, 29, 16, 12, 41, 0, 303, 0)</td>\n",
       "      <td>The Landau-Kolmogorov problem consists of find...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'term': 'math.NA', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>Landau--Kolmogorov inequality revisited</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2012-10-29T16:12:41Z</td>\n",
       "      <td>(2012, 10, 29, 16, 12, 41, 0, 303, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>23 pages, 7 figures</td>\n",
       "      <td>{'term': 'cond-mat.mtrl-sci', 'scheme': 'http:...</td>\n",
       "      <td>http://arxiv.org/abs/1602.00450v1</td>\n",
       "      <td>M. Kawasaki</td>\n",
       "      <td>{'name': 'M. Kawasaki'}</td>\n",
       "      <td>[T. C. Fujita, M. Uchida, Y. Kozuka, W. Sano, ...</td>\n",
       "      <td>10.1103/PhysRevB.93.064419</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/1602.00450v1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1602.00450v1</td>\n",
       "      <td>2016-02-01T09:53:30Z</td>\n",
       "      <td>(2016, 2, 1, 9, 53, 30, 0, 32, 0)</td>\n",
       "      <td>Pyrochlore oxides possessing \"all-in-all-out\" ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'term': 'cond-mat.mtrl-sci', 'scheme': 'http...</td>\n",
       "      <td>All-in-all-out magnetic domain wall conduction...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2016-02-01T09:53:30Z</td>\n",
       "      <td>(2016, 2, 1, 9, 53, 30, 0, 32, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'term': 'cs.DC', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>http://arxiv.org/abs/1612.01842v2</td>\n",
       "      <td>Zaid Hussain</td>\n",
       "      <td>{'name': 'Zaid Hussain'}</td>\n",
       "      <td>[Zaid Hussain]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/1612.01842v2</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1612.01842v2</td>\n",
       "      <td>2016-12-06T15:01:47Z</td>\n",
       "      <td>(2016, 12, 6, 15, 1, 47, 1, 341, 0)</td>\n",
       "      <td>Recently, a higher dimensional Eisenstein-Jaco...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'term': 'cs.DC', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>An Improved One-to-All Broadcasting in Higher ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2016-12-07T06:10:53Z</td>\n",
       "      <td>(2016, 12, 7, 6, 10, 53, 2, 342, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>33 pages, 18 figures</td>\n",
       "      <td>{'term': 'math.CO', 'scheme': 'http://arxiv.or...</td>\n",
       "      <td>http://arxiv.org/abs/0705.3599v1</td>\n",
       "      <td>Chris Smyth</td>\n",
       "      <td>{'name': 'Chris Smyth'}</td>\n",
       "      <td>[James McKee, Chris Smyth]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/0705.3599v1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/0705.3599v1</td>\n",
       "      <td>2007-05-24T15:45:39Z</td>\n",
       "      <td>(2007, 5, 24, 15, 45, 39, 3, 144, 0)</td>\n",
       "      <td>We completely describe all integer symmetric m...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'term': 'math.CO', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>Integer symmetric matrices having all their ei...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2007-05-24T15:45:39Z</td>\n",
       "      <td>(2007, 5, 24, 15, 45, 39, 3, 144, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>10 pages, Journal \"Algebra and Discrete Mathem...</td>\n",
       "      <td>{'term': 'math.RA', 'scheme': 'http://arxiv.or...</td>\n",
       "      <td>http://arxiv.org/abs/0811.3325v1</td>\n",
       "      <td>Slavcho Shtrakov</td>\n",
       "      <td>{'name': 'Slavcho Shtrakov'}</td>\n",
       "      <td>[Jorg Koppitz, Slavcho Shtrakov]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/0811.3325v1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/0811.3325v1</td>\n",
       "      <td>2008-11-20T12:28:46Z</td>\n",
       "      <td>(2008, 11, 20, 12, 28, 46, 3, 325, 0)</td>\n",
       "      <td>The extensions of hypersubstitutions are mappi...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'term': 'math.RA', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>On mappings of terms determined by hypersubsti...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>2008-11-20T12:28:46Z</td>\n",
       "      <td>(2008, 11, 20, 12, 28, 46, 3, 325, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  affiliation                                      arxiv_comment  \\\n",
       "0        None                                               None   \n",
       "1        None                                23 pages, 7 figures   \n",
       "2        None                                               None   \n",
       "3        None                               33 pages, 18 figures   \n",
       "4        None  10 pages, Journal \"Algebra and Discrete Mathem...   \n",
       "\n",
       "                              arxiv_primary_category  \\\n",
       "0  {'term': 'math.NA', 'scheme': 'http://arxiv.or...   \n",
       "1  {'term': 'cond-mat.mtrl-sci', 'scheme': 'http:...   \n",
       "2  {'term': 'cs.DC', 'scheme': 'http://arxiv.org/...   \n",
       "3  {'term': 'math.CO', 'scheme': 'http://arxiv.or...   \n",
       "4  {'term': 'math.RA', 'scheme': 'http://arxiv.or...   \n",
       "\n",
       "                           arxiv_url            author  \\\n",
       "0   http://arxiv.org/abs/1210.7708v1    Alexei Shadrin   \n",
       "1  http://arxiv.org/abs/1602.00450v1       M. Kawasaki   \n",
       "2  http://arxiv.org/abs/1612.01842v2      Zaid Hussain   \n",
       "3   http://arxiv.org/abs/0705.3599v1       Chris Smyth   \n",
       "4   http://arxiv.org/abs/0811.3325v1  Slavcho Shtrakov   \n",
       "\n",
       "                  author_detail  \\\n",
       "0    {'name': 'Alexei Shadrin'}   \n",
       "1       {'name': 'M. Kawasaki'}   \n",
       "2      {'name': 'Zaid Hussain'}   \n",
       "3       {'name': 'Chris Smyth'}   \n",
       "4  {'name': 'Slavcho Shtrakov'}   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                   [Alexei Shadrin]   \n",
       "1  [T. C. Fujita, M. Uchida, Y. Kozuka, W. Sano, ...   \n",
       "2                                     [Zaid Hussain]   \n",
       "3                         [James McKee, Chris Smyth]   \n",
       "4                   [Jorg Koppitz, Slavcho Shtrakov]   \n",
       "\n",
       "                          doi  guidislink                                 id  \\\n",
       "0                        None        True   http://arxiv.org/abs/1210.7708v1   \n",
       "1  10.1103/PhysRevB.93.064419        True  http://arxiv.org/abs/1602.00450v1   \n",
       "2                        None        True  http://arxiv.org/abs/1612.01842v2   \n",
       "3                        None        True   http://arxiv.org/abs/0705.3599v1   \n",
       "4                        None        True   http://arxiv.org/abs/0811.3325v1   \n",
       "\n",
       "                   ...                                              pdf_url  \\\n",
       "0                  ...                     http://arxiv.org/pdf/1210.7708v1   \n",
       "1                  ...                    http://arxiv.org/pdf/1602.00450v1   \n",
       "2                  ...                    http://arxiv.org/pdf/1612.01842v2   \n",
       "3                  ...                     http://arxiv.org/pdf/0705.3599v1   \n",
       "4                  ...                     http://arxiv.org/pdf/0811.3325v1   \n",
       "\n",
       "              published                       published_parsed  \\\n",
       "0  2012-10-29T16:12:41Z  (2012, 10, 29, 16, 12, 41, 0, 303, 0)   \n",
       "1  2016-02-01T09:53:30Z      (2016, 2, 1, 9, 53, 30, 0, 32, 0)   \n",
       "2  2016-12-06T15:01:47Z    (2016, 12, 6, 15, 1, 47, 1, 341, 0)   \n",
       "3  2007-05-24T15:45:39Z   (2007, 5, 24, 15, 45, 39, 3, 144, 0)   \n",
       "4  2008-11-20T12:28:46Z  (2008, 11, 20, 12, 28, 46, 3, 325, 0)   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The Landau-Kolmogorov problem consists of find...   \n",
       "1  Pyrochlore oxides possessing \"all-in-all-out\" ...   \n",
       "2  Recently, a higher dimensional Eisenstein-Jaco...   \n",
       "3  We completely describe all integer symmetric m...   \n",
       "4  The extensions of hypersubstitutions are mappi...   \n",
       "\n",
       "                                      summary_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base...   \n",
       "1  {'type': 'text/plain', 'language': None, 'base...   \n",
       "2  {'type': 'text/plain', 'language': None, 'base...   \n",
       "3  {'type': 'text/plain', 'language': None, 'base...   \n",
       "4  {'type': 'text/plain', 'language': None, 'base...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [{'term': 'math.NA', 'scheme': 'http://arxiv.o...   \n",
       "1  [{'term': 'cond-mat.mtrl-sci', 'scheme': 'http...   \n",
       "2  [{'term': 'cs.DC', 'scheme': 'http://arxiv.org...   \n",
       "3  [{'term': 'math.CO', 'scheme': 'http://arxiv.o...   \n",
       "4  [{'term': 'math.RA', 'scheme': 'http://arxiv.o...   \n",
       "\n",
       "                                               title  \\\n",
       "0            Landau--Kolmogorov inequality revisited   \n",
       "1  All-in-all-out magnetic domain wall conduction...   \n",
       "2  An Improved One-to-All Broadcasting in Higher ...   \n",
       "3  Integer symmetric matrices having all their ei...   \n",
       "4  On mappings of terms determined by hypersubsti...   \n",
       "\n",
       "                                        title_detail               updated  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base...  2012-10-29T16:12:41Z   \n",
       "1  {'type': 'text/plain', 'language': None, 'base...  2016-02-01T09:53:30Z   \n",
       "2  {'type': 'text/plain', 'language': None, 'base...  2016-12-07T06:10:53Z   \n",
       "3  {'type': 'text/plain', 'language': None, 'base...  2007-05-24T15:45:39Z   \n",
       "4  {'type': 'text/plain', 'language': None, 'base...  2008-11-20T12:28:46Z   \n",
       "\n",
       "                          updated_parsed  \n",
       "0  (2012, 10, 29, 16, 12, 41, 0, 303, 0)  \n",
       "1      (2016, 2, 1, 9, 53, 30, 0, 32, 0)  \n",
       "2    (2016, 12, 7, 6, 10, 53, 2, 342, 0)  \n",
       "3   (2007, 5, 24, 15, 45, 39, 3, 144, 0)  \n",
       "4  (2008, 11, 20, 12, 28, 46, 3, 325, 0)  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['affiliation', 'arxiv_comment', 'arxiv_primary_category', 'arxiv_url',\n",
       "       'author', 'author_detail', 'authors', 'doi', 'guidislink', 'id',\n",
       "       'journal_reference', 'links', 'pdf_url', 'published',\n",
       "       'published_parsed', 'summary', 'summary_detail', 'tags', 'title',\n",
       "       'title_detail', 'updated', 'updated_parsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, there are many features in this dataset. To predict the topic, I will only be using the text in the summary and title. All of the other features will not be beneficial to the clustering models. Below, I have added a feature \"text\" that is the concatenation of the summary and title. And I have dropped all of the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['summary'] + \" \" + df['title']\n",
    "df = df.drop(columns=['affiliation','arxiv_comment','arxiv_url',\n",
    "                     'author_detail','doi','guidislink','id',\n",
    "                     'pdf_url','links','published','summary_detail',\n",
    "                     'title_detail','updated','updated_parsed',\n",
    "                     'journal_reference','tags','author','authors',\n",
    "                     'published_parsed','summary','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arxiv_primary_category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'term': 'math.NA', 'scheme': 'http://arxiv.or...</td>\n",
       "      <td>The Landau-Kolmogorov problem consists of find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'term': 'cond-mat.mtrl-sci', 'scheme': 'http:...</td>\n",
       "      <td>Pyrochlore oxides possessing \"all-in-all-out\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'term': 'cs.DC', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>Recently, a higher dimensional Eisenstein-Jaco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'term': 'math.CO', 'scheme': 'http://arxiv.or...</td>\n",
       "      <td>We completely describe all integer symmetric m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'term': 'math.RA', 'scheme': 'http://arxiv.or...</td>\n",
       "      <td>The extensions of hypersubstitutions are mappi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              arxiv_primary_category  \\\n",
       "0  {'term': 'math.NA', 'scheme': 'http://arxiv.or...   \n",
       "1  {'term': 'cond-mat.mtrl-sci', 'scheme': 'http:...   \n",
       "2  {'term': 'cs.DC', 'scheme': 'http://arxiv.org/...   \n",
       "3  {'term': 'math.CO', 'scheme': 'http://arxiv.or...   \n",
       "4  {'term': 'math.RA', 'scheme': 'http://arxiv.or...   \n",
       "\n",
       "                                                text  \n",
       "0  The Landau-Kolmogorov problem consists of find...  \n",
       "1  Pyrochlore oxides possessing \"all-in-all-out\" ...  \n",
       "2  Recently, a higher dimensional Eisenstein-Jaco...  \n",
       "3  We completely describe all integer symmetric m...  \n",
       "4  The extensions of hypersubstitutions are mappi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be utilizing the \"arxiv_primary_category\" feature as my outcome variable. However the dataset's version of the feature is too complex. Below, I strip down each primary category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arxiv_primary_category'] = df['arxiv_primary_category'].astype(str).str.replace('{\\'term\\': \\'','').str.replace(r'\\.(.*)','').str.replace(r'\\',(.*)','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['math', 'cond-mat', 'cs', 'astro-ph', 'hep-th', 'physics',\n",
       "       'quant-ph', 'dg-ga', 'hep-ph', 'hep-lat', 'math-ph', 'stat',\n",
       "       'q-bio', 'q-alg', 'gr-qc', 'alg-geom', 'q-fin', 'hep-ex', 'nlin',\n",
       "       'nucl-th', 'econ', 'nucl-ex', 'acc-phys', 'chao-dyn', 'chem-ph',\n",
       "       'cmp-lg', 'funct-an', 'mtrl-th', 'solv-int', 'eess', 'adap-org',\n",
       "       'comp-gas', 'patt-sol'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arxiv_primary_category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the categories stripped down there are much fewer unique outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "math        5789\n",
       "cs           995\n",
       "hep-th       730\n",
       "cond-mat     557\n",
       "quant-ph     510\n",
       "astro-ph     476\n",
       "hep-ph       472\n",
       "physics      445\n",
       "gr-qc        243\n",
       "math-ph      222\n",
       "hep-lat       98\n",
       "nlin          90\n",
       "q-bio         79\n",
       "nucl-th       67\n",
       "stat          58\n",
       "hep-ex        39\n",
       "q-fin         25\n",
       "alg-geom      25\n",
       "q-alg         20\n",
       "chao-dyn      11\n",
       "dg-ga         10\n",
       "solv-int      10\n",
       "nucl-ex        7\n",
       "eess           6\n",
       "econ           4\n",
       "funct-an       4\n",
       "cmp-lg         2\n",
       "acc-phys       1\n",
       "adap-org       1\n",
       "mtrl-th        1\n",
       "comp-gas       1\n",
       "chem-ph        1\n",
       "patt-sol       1\n",
       "Name: arxiv_primary_category, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arxiv_primary_category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am looking at the value counts so I can resample the topics I will be focusing on. Of the 100,000 papers I pulled, 5789 are mathematics, 995 are computer science, and 445 are physics. I will need to downsample the mathematics and upsample the computer science and physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_math = df.loc[df['arxiv_primary_category'] == 'math']\n",
    "df_cs = df.loc[df['arxiv_primary_category'] == 'cs']\n",
    "df_physics = df.loc[df['arxiv_primary_category'] == 'physics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_math = resample(df_math, replace=False, n_samples=1000, random_state=123)\n",
    "df_cs = resample(df_cs, replace=True, n_samples=1000, random_state=123)\n",
    "df_physics = resample(df_physics, replace=True, n_samples=1000, random_state=123)\n",
    "\n",
    "df2 = pd.concat([df_math, df_cs, df_physics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df2['arxiv_primary_category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now my new dataframe only consists of 1000 papers of each mathematics, computer science, and physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(df2['text'].astype('unicode').values, batch_size=50,\n",
    "                        n_threads=3):\n",
    "    if doc.is_parsed:\n",
    "        tokens.append([n.text for n in doc])\n",
    "        lemma.append([n.lemma_ for n in doc])\n",
    "        pos.append([n.pos_ for n in doc])\n",
    "    else:\n",
    "        tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "\n",
    "df2['tokens'] = tokens\n",
    "df2['lemma'] = lemma\n",
    "df2['pos'] = pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am tokenizing and parsing the text in the \"text\" feature. This is adding 3 new columns of the tokens, lemmas, and parts of speech for each title and summary. As well as another feature \"text_parsed\" which contains the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text_parsed'] = df2['text'].apply(lambda x: nlp(x).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv_primary_category    0\n",
       "text                      0\n",
       "tokens                    0\n",
       "lemma                     0\n",
       "pos                       0\n",
       "text_parsed               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv_primary_category    object\n",
       "text                      object\n",
       "tokens                    object\n",
       "lemma                     object\n",
       "pos                       object\n",
       "text_parsed               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the features as well as the outcome variable are object types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2['text_parsed']\n",
    "y = df2.arxiv_primary_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am assigning the parsed text feature to X and the primary category (the outcome variable) to y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arrays = np.vstack(X.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is concatenating the word vectors into single arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_norm = normalize(X_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I normalized the X for the clustering models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split my training and test sets as 75% and 25% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 300)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00894463 0.18430158 0.10662436 0.07868079 0.04182838 0.03623129\n",
      " 0.02880336 0.02655186 0.02254033 0.0201946  0.01558373 0.01521377\n",
      " 0.01306235 0.01222345 0.01177035 0.01114411 0.00978005 0.00906268\n",
      " 0.00895969 0.00823114 0.00815126 0.00767209 0.00753836 0.00669841\n",
      " 0.00656575 0.00618652 0.00598505 0.00573699 0.00561091 0.00536741\n",
      " 0.00530023 0.00524479 0.00504084 0.00469268 0.00457017 0.00448889\n",
      " 0.00426207 0.00414235 0.00400096 0.00389312 0.00378171 0.00358737\n",
      " 0.003511   0.0034757  0.00339261 0.0033213  0.00322833 0.00321523\n",
      " 0.00312133 0.00299679 0.00295486 0.00289883 0.00283078 0.00275963\n",
      " 0.00271429 0.00263062 0.00255553 0.00250252 0.00249135 0.00242717\n",
      " 0.00239282 0.00233184 0.00228017 0.00225966 0.00214315 0.00212435\n",
      " 0.00211428 0.00205887 0.00202624 0.00199163 0.00198113 0.00192912\n",
      " 0.00189948 0.00181121 0.00178033 0.00176518 0.00176224 0.00172578\n",
      " 0.00171943 0.00165752 0.00162104 0.00161005 0.00159848 0.00156132\n",
      " 0.00155576 0.00153207 0.00152479 0.00149699 0.00148246 0.00146339\n",
      " 0.00141426 0.0014051  0.00135531 0.00133597 0.00133374 0.00131004\n",
      " 0.00129159 0.00127798 0.00124252 0.00122649]\n",
      "0.9096721\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(100)\n",
    "svd.fit(X_train)\n",
    "\n",
    "print(svd.explained_variance_ratio_)  \n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X originally had 3,000 features. I used Truncated SVD to reduce X down to 100 components which explains approximately 90% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously stated, this dataset will be used on 3 different types of clustering methods which are also of 3 different levels (hard to soft)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_score\n",
    "\n",
    "km = KMeans(n_clusters=3, random_state=42)\n",
    "km.fit(X_train)\n",
    "y_pred = km.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I try k-means clustering which is a type of hard clustering. With k-means, I define the number of clusters or centroids which is 3 for the number of topics I am focusing on. This model defaults to 10 times that the algorithm runs with different centroids and 300 iterations on a single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing k-means clusters against the data:\n",
      "col_0                     0    1    2\n",
      "arxiv_primary_category               \n",
      "cs                      115   17  608\n",
      "math                    257    5  485\n",
      "physics                  15  451  297\n",
      "\n",
      "Homogeneity score: 0.245\n"
     ]
    }
   ],
   "source": [
    "print('Comparing k-means clusters against the data:')\n",
    "print(pd.crosstab(y_train, y_pred))\n",
    "\n",
    "print(\"\\nHomogeneity score: %0.3f\" % homogeneity_score(y_train, km.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, this model does not do a great job of clustering the dataset for each topic. Cluster 0 has a majority of math papers, however there are also a number of computer science papers as well. Cluster 1 seems to be very physics focused (as seen later this is pretty consistent across all three models). Cluster 2 has a large number of each topic. The homogeneity score is very low with a 24.5% accuracy. The drawback for this clustering model in terms of the dataset is the assumption that the clusters are radially symmetrical and have similar variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN (Density-based Spatial Clustering of Applications with Noise) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 4\n",
      "Estimated number of noise points: 55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbs = DBSCAN(eps=0.35, min_samples=3)\n",
    "dbs.fit(X_train)\n",
    "y_pred = dbs.fit_predict(X_train)\n",
    "\n",
    "n_clusters_ = len(set(dbs.labels_)) - (1 if -1 in dbs.labels_ else 0)\n",
    "n_noise_ = list(dbs.labels_).count(-1)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I try DBSCAN clustering which is still a type of hard clustering however unlike k-means the clusters can take arbitrary shapes. Also unlike k-means, I am unable to define the number of clusters. I tried a number of different combination of parameters in regards to the epsilon (maximum distance) and number of minimum points.\n",
    "\n",
    "* Low epsilon, high number of minimum points - results in 0 clusters and all datapoints become noise\n",
    "* Low epsilon, low number of minimum points - large number of clusters but vast majority of datapoints become noise\n",
    "* High epsilon, low number of minimum points - results in 1 cluster and no noise\n",
    "* High epsilon, high number of minimum points - results in 1 cluster and no noise\n",
    "\n",
    "After testing a few different combinations, an epsilon of 0.35 and a number of minimum points of 3 resulted in 4 clusters and minimal noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing DBSCAN clusters against the data:\n",
      "col_0                   -1    0   1   2   3\n",
      "arxiv_primary_category                     \n",
      "cs                       6  731   0   3   0\n",
      "math                    38  709   0   0   0\n",
      "physics                 11  745   4   0   3\n",
      "\n",
      "Homogeneity score: 0.011\n"
     ]
    }
   ],
   "source": [
    "print('Comparing DBSCAN clusters against the data:')\n",
    "print(pd.crosstab(y_train, y_pred))\n",
    "\n",
    "print(\"\\nHomogeneity score: %0.3f\" % homogeneity_score(y_train, dbs.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, this model also did not do a great job of clustering based on the different topics. Even though I was able to create more clusters after tuning the parameters, most of the datapoints ended up in cluster 0. Similarly to k-means, physics had the most datapoints that were assigned to clusters outside of cluster 0. The homogeneity score is extremely low with a 1.1% accuracy. As this model relies on density, that suggests the dataset as a whole is very dense and thus the parameters are extremely sensitive either causing the datapoints to become one cluster or all noise. The drawbacks on this model are its sensitivity to the parameters and it struggles with high dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model (GMM) Clustering ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components=3)\n",
    "gm.fit(X_train)\n",
    "y_pred = gm.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly I try the Gaussian Mixture Model clustering which is a type of soft clustering. This type of clustering is very similar to k-means however, unlike k-means, it takes variance into consideration. The \"weighted\" distances may help with defining the clusters better. With this model, I was able to define the number of clusters to be 3 so the model knew to fit 3 Gaussians. The maximum number of EM iterations is defaulted to 100, however as we will see later the model hits the default convergence threshold of 1e-3 and ends after only 2 EM iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing gaussian mixture clusters against the data:\n",
      "col_0                     0    1    2\n",
      "arxiv_primary_category               \n",
      "cs                       16  604  120\n",
      "math                      5  480  262\n",
      "physics                 449  299   15\n"
     ]
    }
   ],
   "source": [
    "print('Comparing gaussian mixture clusters against the data:')\n",
    "print(pd.crosstab(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20888889, 0.61466667, 0.17644444])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of EM iterations: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of EM iterations: %0.0f\" % gm.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1093.7191838719593"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the per-sample average log-likelihood of the given data X.\n",
    "gm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters created by this model are practically the same as the k-means clusters. Once again, physics is mainly focused in cluster 0 but there are a large number of each topic in cluster 1 and a large number of math and computer science in cluster 2. It appears that the variance did not help the clusters become more defined by each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion ###\n",
    "\n",
    "In conclusion, the dataset appears to be quite dense and has difficulty clustering. The physics papers seem to be better at clustering from the math and computer science papers. I may be able to help diverge the different topics by using more word importance. Currently, physics may have more unique words than math and computer science.\n",
    "\n",
    "### Next Steps ###\n",
    "\n",
    "* Topic Modeling Classifiers\n",
    "* Word Importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
